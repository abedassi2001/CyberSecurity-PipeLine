{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Description\n",
    "\n",
    "#I chose the **Phishing Website Dataset** from Kaggle because it is directly relevant to cybersecurity — an increasingly important field that affects everyone. This dataset contains features extracted from real websites and aims to classify whether a given website is legitimate or a phishing attempt.\n",
    "\n",
    "#This project is interesting because it shows how various small attributes (like the presence of an IP address, abnormal URLs, or HTTPS usage) can reveal malicious intent. Analyzing these features can help improve digital safety and deepen understanding of online threats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2️⃣ System Stage – Phishing Website Dataset\n",
    "\n",
    "# - **File name:** phishing.csv  \n",
    "# - **File size:** Approximately a few MB  \n",
    "# - **File type:** CSV (Comma-Separated Values)  \n",
    "# - **Source:** Kaggle - Phishing Website Detector  \n",
    "# - **Protocol:** Downloaded via HTTPS  \n",
    "# - **Versioning:**  \n",
    "#   - Only one file provided; no formal versions  \n",
    "#   - Project version control is managed via Git  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3️⃣ Metadata\n",
    "\n",
    "# - **Data Types:**  \n",
    "#   All features are binary (0 or 1), with the target column named `class`:  \n",
    "#   - `1` = legitimate website  \n",
    "#   - `-1` = phishing website  \n",
    "\n",
    "# - **Missing Values:**  \n",
    "#   No missing values were found in this dataset. All rows are complete and usable for modeling.\n",
    "\n",
    "# - **Special Values:**  \n",
    "#   No special placeholder values (like “unknown” or -999) were found. The data is clean and well-formatted for direct use in machine learning.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### Feature Explanation for Phishing Website Dataset\n",
    "\n",
    "# | Feature Name        | Description                                                                                   |\n",
    "# |---------------------|-----------------------------------------------------------------------------------------------|\n",
    "# | **Index**           | A unique identifier or serial number for each sample (not used in modeling).                   |\n",
    "# | **UsingIP**         | Whether the website URL uses an IP address instead of a domain name (1 = yes, -1 = no).        |\n",
    "# | **LongURL**         | Whether the URL is unusually long (1 = yes, -1 = no).                                         |\n",
    "# | **ShortURL**        | Whether the URL is suspiciously short (1 = yes, -1 = no).                                     |\n",
    "# | **Symbol@**         | Presence of '@' symbol in URL (1 = yes, -1 = no).                                             |\n",
    "# | **Redirecting//**   | Whether the URL contains '//' after the protocol part (1 = yes, -1 = no).                      |\n",
    "# | **PrefixSuffix-**   | Use of hyphen '-' in the domain name (1 = yes, -1 = no).                                      |\n",
    "# | **SubDomains**      | Number of subdomains (1 = more subdomains than usual, -1 = normal).                            |\n",
    "# | **HTTPS**           | Whether the website uses HTTPS protocol (1 = yes, -1 = no).                                   |\n",
    "# | **DomainRegLen**    | Length of domain registration (1 = short registration period, -1 = long).                      |\n",
    "# | **Favicon**         | Whether the favicon is loaded from the same domain (1 = yes, -1 = no).                        |\n",
    "# | **NonStdPort**      | Use of non-standard port in URL (1 = yes, -1 = no).                                           |\n",
    "# | **HTTPSDomainURL**  | Whether HTTPS is present in the domain name part of the URL (1 = yes, -1 = no).               |\n",
    "# | **RequestURL**      | Whether resources are loaded from an external domain (1 = yes, -1 = no).                      |\n",
    "# | **AnchorURL**       | Whether anchor tags link to external domains (1 = yes, -1 = no).                             |\n",
    "# | **LinksInScriptTags** | Presence of links inside script tags (1 = yes, -1 = no).                                    |\n",
    "# | **ServerFormHandler** | Whether the form handler is on an external server (1 = yes, -1 = no).                       |\n",
    "# | **InfoEmail**       | Whether the website contains email information (1 = yes, -1 = no).                           |\n",
    "# | **AbnormalURL**     | Whether the URL has abnormalities (1 = yes, -1 = no).                                        |\n",
    "# | **WebsiteForwarding** | Whether the website forwards to another URL (1 = yes, -1 = no).                            |\n",
    "# | **StatusBarCust**   | Whether the status bar is customized (1 = yes, -1 = no).                                     |\n",
    "# | **DisableRightClick** | Whether right-click is disabled (1 = yes, -1 = no).                                        |\n",
    "# | **UsingPopupWindow** | Presence of popup windows (1 = yes, -1 = no).                                               |\n",
    "# | **IframeRedirection** | Use of iframes for redirection (1 = yes, -1 = no).                                          |\n",
    "# | **AgeofDomain**     | Domain age (1 = young domain, -1 = old).                                                     |\n",
    "# | **DNSRecording**    | Whether the domain is recorded in DNS (1 = yes, -1 = no).                                   |\n",
    "# | **WebsiteTraffic**  | Website traffic rank (1 = low traffic, -1 = high).                                          |\n",
    "# | **PageRank**        | Page rank of the website (1 = low, -1 = high).                                              |\n",
    "# | **GoogleIndex**     | Whether the website is indexed by Google (1 = no, -1 = yes).                                |\n",
    "# | **LinksPointingToPage** | Number of links pointing to the page (1 = few, -1 = many).                              |\n",
    "# | **StatsReport**     | Whether there are statistical reports about the site (1 = no, -1 = yes).                    |\n",
    "# | **class**           | Target variable: `1` = legitimate website, `-1` = phishing website.                         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fcccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac8847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"phishing.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4808cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix on the current DataFrame (excluding non-numeric columns if any)\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52de15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    unique_vals = X[col].nunique()\n",
    "    print(f\"Feature '{col}' has {unique_vals} unique values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f27830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that favicon and using popupwindow are highly correlated, so we can drop one of them.\n",
    "# PCA wont work well here because alot of the features arent correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca8150",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outlier Analysis\n",
    "\n",
    "### 1. Outliers in Individual Features\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    plt.subplot(len(X.columns)//3 + 1, 3, i)\n",
    "    sns.boxplot(x=X[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba11be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = [\n",
    "    'Index',               # Just a row ID\n",
    "    'AgeofDomain',         # May be missing or unreliable\n",
    "    'DisableRightClick',   # Many legitimate sites also disable right-click\n",
    "    'IframeRedirection',   # Used on both phishing and legit sites\n",
    "    'StatusBarCust',       # Many legit sites customize the status bar\n",
    "    'StatsReport',         # May contain outdated or irrelevant stats\n",
    "    'NonStdPort',          # Rarely used and may not be useful\n",
    "    'WebsiteForwarding',   # Unreliable for classification\n",
    "    'InfoEmail',   # Just the presence of email, weak signal   \n",
    "    'Favicon'     #correlated with usingpopupwindow\n",
    "    'UsingPopupWindow'  # Many legitimate sites use popups for various reasons\n",
    "]\n",
    "\n",
    "# Separate target first before dropping\n",
    "y = df['class']\n",
    "\n",
    "# Drop only columns that exist and exclude 'class' from dropping here\n",
    "cols_to_drop = [col for col in features_to_remove if col in df.columns]\n",
    "X = df.drop(columns=cols_to_drop + ['class'])  # drop unwanted features and the target column\n",
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc08f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: remove outliers using Isolation Forest (contamination=0.01)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "iso = IsolationForest(contamination=0.01, random_state=42)\n",
    "outlier_flags = iso.fit_predict(X)\n",
    "mask_inliers = outlier_flags == 1\n",
    "\n",
    "X, y = X.loc[mask_inliers], y.loc[mask_inliers]  # Use .loc for label-based filtering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c1cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e50abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape:\", X.shape)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c93408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a064af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Print class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y)\n",
    "plt.title('Class Distribution: Legitimate (1) vs Phishing (-1)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01efd979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Count missing values before imputation\n",
    "missing_before = X.isnull().sum()\n",
    "\n",
    "# Impute missing values (returns NumPy array)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed_array = imputer.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame with original column names\n",
    "X_imputed = pd.DataFrame(X_imputed_array, columns=X.columns)\n",
    "\n",
    "# Count missing values after imputation\n",
    "missing_after = X_imputed.isnull().sum()\n",
    "\n",
    "# Plot missing values\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=missing_before.index, y=missing_before.values, color='skyblue')\n",
    "plt.title(\"Missing Values Before Imputation\")\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=missing_after.index, y=missing_after.values, color='lightgreen')\n",
    "plt.title(\"Missing Values After Imputation\")\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693842cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = [col for col in df.columns if df[col].nunique() == 2]\n",
    "\n",
    "for col in binary_cols:\n",
    "    sns.countplot(x=col, data=df)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fdfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proportion of 1s for each feature in X\n",
    "feature_summary = (X == 1).sum() / len(X)\n",
    "\n",
    "# Plot feature presence rate\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_summary.sort_values(ascending=False).plot(kind='bar')\n",
    "plt.title('Feature Presence Rate (Proportion of 1s per Feature)')\n",
    "plt.ylabel('Proportion of 1s')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Split features and target ===\n",
    "# Assumes you already have `X` and `y` from the preprocessed DataFrame\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Standardize numeric features ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === Train the KNN model ===\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# === Simulated Training Progress ===\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    y_pred_train = knn.predict(X_train_scaled)\n",
    "    loss = np.mean(y_pred_train != y_train)\n",
    "    acc = accuracy_score(y_train, y_pred_train)\n",
    "    train_loss.append(loss)\n",
    "    train_accuracy.append(acc)\n",
    "\n",
    "# === Evaluate on test set ===\n",
    "y_pred_test = knn.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Overall model accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# === Feature Importance using Permutation Importance ===\n",
    "result = permutation_importance(knn, X_test_scaled, y_test, n_repeats=10, random_state=42)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': result.importances_mean\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# === Plot Feature Importances ===\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'], color='skyblue')\n",
    "plt.xlabel(\"Mean Importance Score\")\n",
    "plt.title(\"Permutation Feature Importance (KNN)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Plot Training Loss & Accuracy ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(train_loss) + 1), train_loss, marker='o', label='Training Loss')\n",
    "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, marker='o', label='Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('KNN Training Loss and Accuracy (Simulated)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce56541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Split features and target ===\n",
    "# Assumes you already have `X` and `y` from the preprocessed DataFrame\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Standardize numeric features ===\n",
    "# (Random Forests don't require feature scaling, but scaling won't hurt)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === Train Random Forest model ===\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# === Evaluate on test set ===\n",
    "y_pred_test = rf.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Overall model accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# === Feature Importances from Random Forest ===\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# === Plot Feature Importances ===\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'], color='forestgreen')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57030be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "importances = rf.feature_importances_\n",
    "indices = importances.argsort()[::-1]\n",
    "features = X.columns\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=importances[indices], y=features[indices])\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d758b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming you already have your trained model `rf` and test data X_test_scaled, y_test\n",
    "y_pred_test = rf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate basic performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_test, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_test, pos_label=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Confusion Matrix plot\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Phishing', 'Legit'], yticklabels=['Phishing', 'Legit'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve and AUC (if your model provides probability predictions)\n",
    "if hasattr(rf, \"predict_proba\"):\n",
    "    y_scores = rf.predict_proba(X_test_scaled)[:,1]  # Probability of positive class (legit)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_scores, pos_label=1)\n",
    "    auc_score = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.4f})')\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99105adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming you have your trained KNN model `knn`, and test data X_test_scaled, y_test\n",
    "\n",
    "# Predict test labels\n",
    "y_pred_test = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_test, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_test, pos_label=1)\n",
    "\n",
    "print(f\"KNN Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"KNN Model Precision: {precision:.4f}\")\n",
    "print(f\"KNN Model Recall: {recall:.4f}\")\n",
    "print(f\"KNN Model F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Phishing', 'Legit'], yticklabels=['Phishing', 'Legit'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('KNN Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve and AUC for KNN (if predict_proba available)\n",
    "if hasattr(knn, \"predict_proba\"):\n",
    "    y_scores = knn.predict_proba(X_test_scaled)[:,1]  # Probability for class '1' (legit)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_scores, pos_label=1)\n",
    "    auc_score = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.4f})')\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('KNN ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"KNN model does not support probability prediction; ROC curve cannot be plotted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf8de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Conclusion\n",
    "\n",
    "# The **K-Nearest Neighbors (KNN)** classifier performed well on the phishing website dataset, achieving an accuracy of approximately **93.85%**, with precision, recall, and F1-scores all above **94%**. Using a **Random Forest** classifier improved the performance further, reaching an accuracy of about **96.11%** and similarly high precision, recall, and F1-scores.\n",
    "\n",
    "# This indicates that both models are effective at distinguishing legitimate websites from phishing attempts, with Random Forest showing better overall classification metrics due to its ability to capture more complex relationships between features.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## how can we improve the model?\n",
    "# To improve the model's performance further, consider the following strategies:\n",
    "# 1. **Feature Engineering:**  \n",
    "#    - Analyze feature importance and remove irrelevant or noisy features.  \n",
    "#    - Create new features that might better capture phishing behavior.\n",
    "\n",
    "# 2. **Hyperparameter Tuning:**  \n",
    "#    - For KNN: Tune the number of neighbors (`k`), distance metrics, and weighting.  \n",
    "#    - For Random Forest: Tune number of trees, max depth, minimum samples per leaf, etc.\n",
    "\n",
    "# 3. **Handling Class Imbalance:**  \n",
    "#    - Verify class balance; if imbalanced, consider SMOTE, class weighting, or balanced sampling.\n",
    "\n",
    "# 4. **Cross-Validation:**  \n",
    "#    - Use k-fold cross-validation to better evaluate model generalization.\n",
    "\n",
    "# 5. **Model Comparison:**  \n",
    "#    - Experiment with other algorithms like Gradient Boosting, SVM, or Neural Networks.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## Potential Problems and Limitations\n",
    "\n",
    "# - **Data Quality and Feature Reliability:**  \n",
    "#   Some features may be noisy or weak predictors, potentially impacting model generalization.\n",
    "\n",
    "# - **Overfitting Risk:**  \n",
    "#   Random Forests can overfit if hyperparameters are not carefully tuned.\n",
    "\n",
    "# - **Real-world Applicability:**  \n",
    "#   Dataset may not reflect all modern phishing techniques, requiring periodic model updates.\n",
    "\n",
    "# - **Interpretability:**  \n",
    "#   While KNN is simple, Random Forests are complex; interpretability tools like SHAP or feature importance should be used to understand predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
